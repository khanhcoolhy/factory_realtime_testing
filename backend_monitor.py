import os
import time
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import joblib
import requests
from supabase import create_client
from datetime import datetime, timedelta

# ===============================================================
# 1. C·∫§U H√åNH & KH·ªûI T·∫†O
# ===============================================================
print("üïµÔ∏è MONITOR: Kh·ªüi ƒë·ªông h·ªá th·ªëng gi√°m s√°t Backend (Mapping L√†n 1-4)...")

MODEL_PATH = "saved_models_v2/lstm_factory_v2.pth"
SCALER_PATH = "saved_models_v2/robust_scaler_v2.pkl"
CONFIG_PATH = "saved_models_v2/model_config_v2.pkl"

# --- MAPPING C·∫§U H√åNH (S·ª¨A PH·∫¶N N√ÄY ƒê·ªÇ KH·ªöP APP) ---
# Logic: √Ånh x·∫° t·ª´ (Device ID + Channel v·∫≠t l√Ω) -> T√™n L√†n hi·ªÉn th·ªã
LANE_MAPPING = {
    "4417930D77DA": {"01": "L√†n 1", "02": "L√†n 2"},  # M√°y 1
    "AC0BFBCE8797": {"01": "L√†n 3", "02": "L√†n 4"}   # M√°y 2
}

# L·∫•y danh s√°ch ƒë·ªÉ loop
DEVICES = list(LANE_MAPPING.keys())
CHANNELS = ["01", "02"] # Channel v·∫≠t l√Ω t·ª´ DB

TEMP_CRASH_THRESHOLD = 40.0 

# L·∫•y Secrets
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("‚ùå L·ªói: Thi·∫øu Key Supabase (Set environment variable)")
    exit()

try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"‚ùå L·ªói k·∫øt n·ªëi DB: {e}")
    exit()

# ===============================================================
# 2. LOAD AI MODEL (Gi·ªëng h·ªát Notebook & App)
# ===============================================================
def load_ai():
    if not os.path.exists(MODEL_PATH):
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file model. Ch·∫°y ch·∫ø ƒë·ªô Rule-based.")
        return None, None, None
    try:
        cfg = joblib.load(CONFIG_PATH)
        scl = joblib.load(SCALER_PATH)
        
        class LSTMModel(nn.Module):
            def __init__(self, n_features, hidden_dim=128, num_layers=3, dropout=0.2):
                super(LSTMModel, self).__init__()
                self.lstm = nn.LSTM(n_features, hidden_dim, num_layers, batch_first=True, dropout=dropout)
                self.fc = nn.Linear(hidden_dim, n_features)
            def forward(self, x):
                out, _ = self.lstm(x)
                out = self.fc(out[:, -1, :])
                return out

        model = LSTMModel(n_features=cfg['n_features'], hidden_dim=cfg['hidden_dim'])
        model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
        model.eval()
        print("‚úÖ ƒê√£ load xong AI Model v2")
        return model, scl, cfg
    except Exception as e:
        print(f"‚ùå L·ªói load AI: {e}")
        return None, None, None

model, scaler, config = load_ai()

# ===============================================================
# 3. H√ÄM X·ª¨ L√ù
# ===============================================================
def send_telegram(message):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("   [Log] Ch∆∞a c·∫•u h√¨nh Telegram.")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
    try:
        requests.post(url, json=payload, timeout=5)
    except Exception as e:
        print(f"‚ùå L·ªói g·ª≠i Telegram: {e}")

def check_system():
    print(f"\n--- Qu√©t l√∫c {datetime.now().strftime('%H:%M:%S')} ---")
    
    # L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t (ƒë·ªß cho 4 l√†n)
    try:
        response = supabase.table("sensor_data").select("*").order("time", desc=True).limit(500).execute()
        df = pd.DataFrame(response.data)
        if df.empty:
            print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu.")
            return
        
        # Convert Time
        df['time'] = pd.to_datetime(df['time'], format='mixed', utc=True)
        # Sort ƒë·ªÉ l·∫•y tail ch√≠nh x√°c
        df = df.sort_values('time')
    except Exception as e:
        print(f"‚ùå L·ªói query DB: {e}")
        return

    # Loop qua t·ª´ng thi·∫øt b·ªã v√† t·ª´ng k√™nh
    for dev_id in DEVICES:
        for ch in CHANNELS:
            # L·∫•y t√™n hi·ªÉn th·ªã (L√†n 1, 2, 3, 4)
            lane_name = LANE_MAPPING.get(dev_id, {}).get(ch, f"Unknown-{ch}")
            
            # L·ªçc data cho l√†n n√†y
            df_lane = df[(df['DevAddr'] == dev_id) & (df['Channel'] == ch)]
            
            if df_lane.empty:
                continue
                
            last_row = df_lane.iloc[-1]
            
            # --- KI·ªÇM TRA LOGIC ---
            
            # 1. Offline Check
            time_diff = (datetime.now(last_row['time'].tzinfo) - last_row['time']).total_seconds()
            if time_diff > 300: # 5 ph√∫t
                print(f"‚ö†Ô∏è {lane_name}: M·∫•t k·∫øt n·ªëi ({int(time_diff)}s)")
                # (T√πy ch·ªçn: G·ª≠i c·∫£nh b√°o offline)
                continue

            # 2. Rule-based Crash Check (Quan tr·ªçng)
            if last_row['Speed'] == 0 and last_row['Temp'] > TEMP_CRASH_THRESHOLD:
                msg = (
                    f"üî• **C·∫¢NH B√ÅO NGUY HI·ªÇM - {lane_name}**\n"
                    f"---------------\n"
                    f"üå°Ô∏è Nhi·ªát ƒë·ªô: {last_row['Temp']}¬∞C (Qu√° cao)\n"
                    f"üõë Tr·∫°ng th√°i: D·ª´ng m√°y ƒë·ªôt ng·ªôt\n"
                    f"‚è∞ Th·ªùi gian: {last_row['time'].strftime('%H:%M:%S')}"
                )
                print(f"   -> üî¥ {lane_name}: CRASH DETECTED!")
                send_telegram(msg)
                continue # ƒê√£ crash th√¨ kh√¥ng check AI n·ªØa

            # 3. AI Anomaly Check
            if model and len(df_lane) > 31: # C·∫ßn ƒë·ªß sequence length
                try:
                    features = config['features_list']
                    data_segment = df_lane[features].tail(31).values
                    
                    # Preprocessing gi·ªëng Training
                    data_log = np.log1p(data_segment)
                    data_scaled = scaler.transform(data_log)
                    
                    X_input = torch.tensor(data_scaled[:-1], dtype=torch.float32).unsqueeze(0)
                    Y_actual = data_scaled[-1]
                    
                    with torch.no_grad():
                        Y_pred = model(X_input).numpy()[0]
                    
                    target_idx = config.get('target_cols_idx', [0, 1, 2])
                    loss = np.mean(np.abs(Y_pred[target_idx] - Y_actual[target_idx]))
                    
                    # Ng∆∞·ª°ng (Threshold)
                    threshold = config['threshold']
                    
                    if loss > threshold:
                        err_type = "üê¢ K·∫πt t·∫£i / Ch·∫≠m" if last_row['Speed'] < 1.5 else "‚ö†Ô∏è Rung l·∫Øc / Qu√° t·∫£i"
                        msg = (
                            f"ü§ñ **PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG - {lane_name}**\n"
                            f"---------------\n"
                            f"üìâ AI Loss: **{loss:.4f}** (Ng∆∞·ª°ng: {threshold:.3f})\n"
                            f"üîß Ph√°n ƒëo√°n: {err_type}\n"
                            f"üèéÔ∏è T·ªëc ƒë·ªô: {last_row['Speed']} m/s\n"
                            f"üå°Ô∏è Nhi·ªát ƒë·ªô: {last_row['Temp']}¬∞C"
                        )
                        print(f"   -> üü† {lane_name}: AI ANOMALY (Loss: {loss:.3f})")
                        send_telegram(msg)
                    else:
                        print(f"   -> ‚úÖ {lane_name}: ·ªîn ƒë·ªãnh (Loss: {loss:.3f})")
                        
                except Exception as e:
                    print(f"   -> ‚ö†Ô∏è L·ªói t√≠nh to√°n AI cho {lane_name}: {e}")

# ===============================================================
# 4. LOOP CH√çNH
# ===============================================================
if __name__ == "__main__":
    while True:
        check_system()
        time.sleep(10) # 10 gi√¢y qu√©t 1 l·∫ßn