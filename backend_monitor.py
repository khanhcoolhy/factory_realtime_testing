import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import joblib
import requests
from supabase import create_client
from datetime import datetime, timedelta

# ===============================================================
# 1. Cáº¤U HÃŒNH & KHá»I Táº O
# ===============================================================
print("ğŸ•µï¸ MONITOR: Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng giÃ¡m sÃ¡t Backend (AI Logic Update)...")

# CÃ¡c file Model (Pháº£i cÃ³ sáºµn trong repo GitHub/Folder)
MODEL_PATH = "lstm_factory_v2.pth"
SCALER_PATH = "robust_scaler_v2.pkl"
CONFIG_PATH = "model_config_v2.pkl"

# Danh sÃ¡ch thiáº¿t bá»‹ vÃ  cÃ¡c lÃ n (Channel) cáº§n giÃ¡m sÃ¡t
DEVICES_CONFIG = [
    {"id": "4417930D77DA", "channels": ["01", "02"]},
    {"id": "AC0BFBCE8797", "channels": ["01", "02"]}
]

# Láº¥y Secrets tá»« biáº¿n mÃ´i trÆ°á»ng
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

# Kiá»ƒm tra biáº¿n mÃ´i trÆ°á»ng
if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ Lá»—i: Thiáº¿u Key SUPABASE_URL hoáº·c SUPABASE_KEY!")
    exit(1)

# Káº¿t ná»‘i Supabase
try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Lá»—i káº¿t ná»‘i Supabase: {e}")
    exit(1)

# ===============================================================
# 2. LOAD AI MODEL
# ===============================================================
def load_ai():
    if not os.path.exists(MODEL_PATH): 
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file model: {MODEL_PATH}")
        return None, None, None
    
    try:
        # Load Config & Scaler
        cfg = joblib.load(CONFIG_PATH)
        scl = joblib.load(SCALER_PATH)
        
        # Äá»‹nh nghÄ©a láº¡i kiáº¿n trÃºc máº¡ng LSTM (pháº£i khá»›p lÃºc train)
        class LSTMModel(nn.Module):
            def __init__(self, n_features, hidden_dim=128, num_layers=3, dropout=0.2):
                super(LSTMModel, self).__init__()
                self.lstm = nn.LSTM(n_features, hidden_dim, num_layers, batch_first=True, dropout=dropout)
                self.fc = nn.Linear(hidden_dim, n_features)
            def forward(self, x):
                out, _ = self.lstm(x)
                out = self.fc(out[:, -1, :])
                return out

        # Load Weights
        model = LSTMModel(n_features=cfg['n_features'], hidden_dim=cfg['hidden_dim'])
        model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
        model.eval()
        
        print("âœ… ÄÃ£ load xong Model AI & Scaler.")
        return model, scl, cfg
    except Exception as e:
        print(f"âŒ Lá»—i khi load AI Model: {e}")
        return None, None, None

# Load model ngay khi script cháº¡y
model, scaler, config = load_ai()

# ===============================================================
# 3. HÃ€M Gá»¬I TELEGRAM
# ===============================================================
def send_telegram(msg):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID: 
        print("âš ï¸ KhÃ´ng cÃ³ Token Telegram, bá» qua gá»­i tin nháº¯n.")
        return
    
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID, 
        "text": msg, 
        "parse_mode": "Markdown"
    }
    
    try:
        resp = requests.post(url, json=payload, timeout=5)
        if resp.status_code != 200:
            print(f"âš ï¸ Gá»­i Telegram tháº¥t báº¡i: {resp.text}")
    except Exception as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i Telegram: {e}")

# ===============================================================
# 4. LOGIC KIá»‚M TRA (CORE LOGIC ÄÃƒ ÄÆ¯á»¢C LÃ€M Má»šI)
# ===============================================================
def check_lane_status(dev_id, channel_id):
    print(f"\nğŸ” Äang kiá»ƒm tra: {dev_id} - LÃ n {channel_id}...")
    
    try:
        # 1. Láº¥y dá»¯ liá»‡u má»›i nháº¥t tá»« Supabase cho Ä‘Ãºng LÃ n (Channel)
        response = supabase.table("sensor_data")\
            .select("*")\
            .eq("DevAddr", dev_id)\
            .eq("Channel", channel_id)\
            .order("time", desc=True)\
            .limit(40)\
            .execute()
            
        df = pd.DataFrame(response.data)
        
        if df.empty: 
            print("   -> âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u trong DB.")
            return
        
        # Sáº¯p xáº¿p láº¡i theo thá»i gian tÄƒng dáº§n (Ä‘á»ƒ cháº¡y Sequence Time Series)
        df['time'] = pd.to_datetime(df['time'])
        df = df.sort_values('time')
        last_row = df.iloc[-1]
        
        # 2. Kiá»ƒm tra Máº¥t káº¿t ná»‘i (Offline Check)
        now_utc = datetime.utcnow()
        last_time_utc = last_row['time'].replace(tzinfo=None)
        time_diff = (now_utc - last_time_utc).total_seconds()
        
        if time_diff > 1500: # 25 phÃºt
            print(f"   -> âŒ Thiáº¿t bá»‹ máº¥t káº¿t ná»‘i ({int(time_diff/60)} phÃºt trÆ°á»›c).")
            return

        # 3. Kiá»ƒm tra MÃ¡y Dá»«ng (Idle Check)
        # Náº¿u Speed = 0, ta coi nhÆ° mÃ¡y Ä‘ang nghá»‰, khÃ´ng cáº§n cháº¡y AI
        if last_row['Speed'] == 0:
            print("   -> ğŸ’¤ MÃ¡y Ä‘ang nghá»‰ (Speed=0). Bá» qua AI.")
            return

        # 4. LOGIC AI (Anomaly Detection)
        # -----------------------------------------------------------
        SEQ_LEN = 30
        
        # Kiá»ƒm tra Ä‘á»§ Ä‘á»™ dÃ i dá»¯ liá»‡u
        if len(df) < SEQ_LEN + 1:
            print(f"   -> âš ï¸ KhÃ´ng Ä‘á»§ dá»¯ liá»‡u liÃªn tá»¥c (Cáº§n {SEQ_LEN+1}, cÃ³ {len(df)}).")
            return
            
        if model is None:
            return # Model chÆ°a load Ä‘Æ°á»£c

        # Chuáº©n bá»‹ input (Váº«n láº¥y cáº£ Temp/Humidity Ä‘á»ƒ khá»›p vá»›i input model 5 chiá»u)
        features = config['features_list']
        try:
            data_segment = df[features].tail(SEQ_LEN + 1).values
        except KeyError as e:
             print(f"   -> âŒ Thiáº¿u cá»™t dá»¯ liá»‡u: {e}")
             return

        # Transform (Log -> Scale)
        data_log = np.log1p(data_segment)
        data_scaled = scaler.transform(data_log)
        
        # TÃ¡ch Input (30 dÃ²ng Ä‘áº§u) vÃ  Output thá»±c táº¿ (dÃ²ng 31)
        X_input = torch.tensor(data_scaled[:-1], dtype=torch.float32).unsqueeze(0)
        Y_actual = data_scaled[-1]
        
        # AI Dá»± bÃ¡o
        with torch.no_grad():
            Y_pred = model(X_input).numpy()[0]
        
        # TÃ­nh sai sá»‘ (Loss) trÃªn cÃ¡c cá»™t quan trá»ng (Speed, RunTime, HeldTime)
        target_idx = config.get('target_cols_idx', [0, 1, 2])
        loss = np.mean(np.abs(Y_pred[target_idx] - Y_actual[target_idx]))
        
        # 5. PHÃ‚N LOáº I Lá»–I (Dá»±a trÃªn HÃ nh vi Speed)
        # -----------------------------------------------------------
        if loss > config['threshold']:
            # TÃ­nh tá»‘c Ä‘á»™ trung bÃ¬nh cá»§a chuá»—i dá»¯ liá»‡u vá»«a láº¥y
            avg_speed_segment = df['Speed'].tail(SEQ_LEN).mean()
            
            # Logic phÃ¢n loáº¡i:
            # - Náº¿u Speed hiá»‡n táº¡i tháº¥p hÆ¡n 50% Speed trung bÃ¬nh -> Káº¹t táº£i
            # - NgÆ°á»£c láº¡i (Speed váº«n cao nhÆ°ng Loss cao) -> Cháº¡y khÃ´ng Ä‘á»u/Rung láº¯c
            if last_row['Speed'] < (avg_speed_segment * 0.5):
                err_type = "ğŸ¢ Káº¹t táº£i / Tá»‘c Ä‘á»™ sá»¥t giáº£m"
                emoji = "ğŸ¢"
            else:
                err_type = "âš ï¸ Rung láº¯c / Hoáº¡t Ä‘á»™ng báº¥t á»•n"
                emoji = "ğŸ“‰"
                
            msg = (
                f"{emoji} **Cáº¢NH BÃO Váº¬N HÃ€NH (AI)**\n"
                f"---------------\n"
                f"ğŸ¤– Thiáº¿t bá»‹: `{dev_id}`\n"
                f"ğŸ›¤ï¸ LÃ n (Channel): `{channel_id}`\n"
                f"ğŸ”¥ Sai sá»‘ AI (Loss): **{loss:.3f}** (NgÆ°á»¡ng: {config['threshold']:.2f})\n"
                f"ğŸ”§ Cháº©n Ä‘oÃ¡n: {err_type}\n"
                f"ğŸï¸ Tá»‘c Ä‘á»™: {last_row['Speed']} (TB: {avg_speed_segment:.1f})\n"
                f"ğŸ•’ LÃºc: {last_row['time'].strftime('%H:%M:%S')}\n"
            )
            print(f"   -> ğŸŸ  Báº¤T THÆ¯á»œNG: {err_type} (Loss: {loss:.3f})")
            send_telegram(msg)
        else:
            print(f"   -> âœ… Hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng (Loss: {loss:.3f})")

    except Exception as e:
        print(f"âŒ Lá»—i Runtime táº¡i {dev_id}-{channel_id}: {e}")

# ===============================================================
# 5. MAIN LOOP
# ===============================================================
if __name__ == "__main__":
    # Láº·p qua tá»«ng thiáº¿t bá»‹ vÃ  tá»«ng kÃªnh cá»§a thiáº¿t bá»‹ Ä‘Ã³
    for device_conf in DEVICES_CONFIG:
        d_id = device_conf["id"]
        channels = device_conf["channels"]
        
        for ch in channels:
            check_lane_status(d_id, ch)
    
    print("\nğŸ Káº¿t thÃºc phiÃªn giÃ¡m sÃ¡t.")