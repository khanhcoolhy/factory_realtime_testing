import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import joblib
import requests
from supabase import create_client
from datetime import datetime, timedelta

# ===============================================================
# 1. C·∫§U H√åNH & KH·ªûI T·∫†O
# ===============================================================
print("üïµÔ∏è MONITOR: Kh·ªüi ƒë·ªông h·ªá th·ªëng gi√°m s√°t Backend...")

# C√°c file Model (Ph·∫£i c√≥ s·∫µn trong repo GitHub)
MODEL_PATH = "lstm_factory_v2.pth"
SCALER_PATH = "robust_scaler_v2.pkl"
CONFIG_PATH = "model_config_v2.pkl"

# Danh s√°ch thi·∫øt b·ªã c·∫ßn gi√°m s√°t
DEVICES = ["4417930D77DA", "AC0BFBCE8797"]

# Ng∆∞·ª°ng nhi·ªát ƒë·ªô ƒë·ªÉ x√°c ƒë·ªãnh m√°y ch·∫øt (Crash) khi Speed = 0
TEMP_CRASH_THRESHOLD = 40.0 

# L·∫•y Secrets t·ª´ bi·∫øn m√¥i tr∆∞·ªùng (Github Actions s·∫Ω t·ª± ƒëi·ªÅn v√†o)
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

# Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng
if not SUPABASE_URL or not SUPABASE_KEY:
    print("‚ùå L·ªói: Thi·∫øu Key SUPABASE_URL ho·∫∑c SUPABASE_KEY!")
    exit(1)

# K·∫øt n·ªëi Supabase
try:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"‚ùå L·ªói k·∫øt n·ªëi Supabase: {e}")
    exit(1)

# ===============================================================
# 2. LOAD AI MODEL
# ===============================================================
def load_ai():
    if not os.path.exists(MODEL_PATH): 
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file model: {MODEL_PATH}")
        return None, None, None
    
    try:
        # Load Config & Scaler
        cfg = joblib.load(CONFIG_PATH)
        scl = joblib.load(SCALER_PATH)
        
        # ƒê·ªãnh nghƒ©a l·∫°i ki·∫øn tr√∫c m·∫°ng LSTM (ph·∫£i kh·ªõp l√∫c train)
        class LSTMModel(nn.Module):
            def __init__(self, n_features, hidden_dim=128, num_layers=3, dropout=0.2):
                super(LSTMModel, self).__init__()
                self.lstm = nn.LSTM(n_features, hidden_dim, num_layers, batch_first=True, dropout=dropout)
                self.fc = nn.Linear(hidden_dim, n_features)
            def forward(self, x):
                out, _ = self.lstm(x)
                out = self.fc(out[:, -1, :])
                return out

        # Load Weights
        model = LSTMModel(n_features=cfg['n_features'], hidden_dim=cfg['hidden_dim'])
        model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
        model.eval()
        
        print("‚úÖ ƒê√£ load xong Model AI & Scaler.")
        return model, scl, cfg
    except Exception as e:
        print(f"‚ùå L·ªói khi load AI Model: {e}")
        return None, None, None

# Load model ngay khi script ch·∫°y
model, scaler, config = load_ai()

# ===============================================================
# 3. H√ÄM G·ª¨I TELEGRAM
# ===============================================================
def send_telegram(msg):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID: 
        print("‚ö†Ô∏è Kh√¥ng c√≥ Token Telegram, b·ªè qua g·ª≠i tin nh·∫Øn.")
        return
    
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID, 
        "text": msg, 
        "parse_mode": "Markdown"
    }
    
    try:
        resp = requests.post(url, json=payload, timeout=5)
        if resp.status_code == 200:
            print("üì® ƒê√£ g·ª≠i c·∫£nh b√°o Telegram th√†nh c√¥ng.")
        else:
            print(f"‚ö†Ô∏è G·ª≠i Telegram th·∫•t b·∫°i: {resp.text}")
    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi Telegram: {e}")

# ===============================================================
# 4. LOGIC KI·ªÇM TRA (CORE)
# ===============================================================
def check_device_status(dev_id):
    print(f"\nüîç ƒêang ki·ªÉm tra thi·∫øt b·ªã: {dev_id}...")
    
    # 1. L·∫•y d·ªØ li·ªáu t·ª´ Supabase (L·∫•y d∆∞ 40 d√≤ng ƒë·ªÉ ch·∫Øc ƒÉn)
    try:
        response = supabase.table("sensor_data")\
            .select("*")\
            .eq("DevAddr", dev_id)\
            .order("time", desc=True)\
            .limit(40)\
            .execute()
            
        df = pd.DataFrame(response.data)
        
        if df.empty: 
            print("   -> ‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu trong DB.")
            return
        
        # S·∫Øp x·∫øp l·∫°i theo th·ªùi gian tƒÉng d·∫ßn (C≈© -> M·ªõi) ƒë·ªÉ ƒë∆∞a v√†o LSTM
        df['time'] = pd.to_datetime(df['time'])
        df = df.sort_values('time')
        
        # L·∫•y d√≤ng m·ªõi nh·∫•t ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i hi·ªán t·∫°i
        last_row = df.iloc[-1]
        
        # 2. Ki·ªÉm tra t√≠nh m·ªõi c·ªßa d·ªØ li·ªáu (Staleness Check)
        # N·∫øu d·ªØ li·ªáu c≈© qu√° 25 ph√∫t -> Worker c√≥ th·ªÉ ƒë√£ ch·∫øt -> Kh√¥ng b√°o l·ªói m√°y h·ªèng
        now_utc = datetime.utcnow()
        last_time_utc = last_row['time'].replace(tzinfo=None)
        time_diff = (now_utc - last_time_utc).total_seconds()
        
        if time_diff > 1500: # 1500s = 25 ph√∫t
            print(f"   -> üí§ D·ªØ li·ªáu qu√° c≈© ({int(time_diff/60)} ph√∫t tr∆∞·ªõc). B·ªè qua.")
            return

        # 3. LOGIC PH√ÅT HI·ªÜN S·ª∞ C·ªê (CRASH) - Rule Based
        # Speed = 0 nh∆∞ng Nhi·ªát ƒë·ªô cao -> M√°y d·ª´ng ƒë·ªôt ng·ªôt
        if last_row['Speed'] == 0:
            if last_row['Temp'] > TEMP_CRASH_THRESHOLD:
                msg = (
                    f"üö® **C·∫¢NH B√ÅO S·ª∞ C·ªê (CRASH)**\n"
                    f"---------------\n"
                    f"ü§ñ Thi·∫øt b·ªã: `{dev_id}`\n"
                    f"üå°Ô∏è Nhi·ªát ƒë·ªô: **{last_row['Temp']}¬∞C** (Qu√° n√≥ng!)\n"
                    f"üõë T·ªëc ƒë·ªô: 0\n"
                    f"üïí L√∫c: {last_row['time'].strftime('%H:%M:%S')}\n"
                    f"---------------\n"
                    f"‚ö†Ô∏è *M√°y d·ª´ng ƒë·ªôt ng·ªôt, vui l√≤ng ki·ªÉm tra ngay!*"
                )
                print("   -> üî¥ PH√ÅT HI·ªÜN CRASH!")
                send_telegram(msg)
            else:
                print("   -> üí§ M√°y ƒëang ngh·ªâ (Idle) - Nhi·ªát ƒë·ªô th·∫•p.")
            return # N·∫øu Speed = 0 th√¨ kh√¥ng ch·∫°y AI n·ªØa

        # 4. LOGIC AI (Anomaly Detection) - Khi Speed > 0
        SEQ_LEN = 30
        
        # Ki·ªÉm tra ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ch·∫°y AI kh√¥ng
        if len(df) < SEQ_LEN + 1:
            print(f"   -> ‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu li√™n t·ª•c (C·∫ßn {SEQ_LEN+1}, c√≥ {len(df)}).")
            return
            
        if model is None:
            print("   -> ‚ö†Ô∏è Model ch∆∞a load ƒë∆∞·ª£c, b·ªè qua b∆∞·ªõc AI.")
            return

        # Chu·∫©n b·ªã d·ªØ li·ªáu cho Model
        features = config['features_list']
        try:
            # L·∫•y ƒë√∫ng ƒëo·∫°n d·ªØ li·ªáu cu·ªëi c√πng
            data_segment = df[features].tail(SEQ_LEN + 1).values
        except KeyError as e:
             print(f"   -> ‚ùå Thi·∫øu c·ªôt d·ªØ li·ªáu: {e}")
             return

        # Transform (Log -> Scale)
        data_log = np.log1p(data_segment)
        data_scaled = scaler.transform(data_log)
        
        X_input = torch.tensor(data_scaled[:-1], dtype=torch.float32).unsqueeze(0)
        Y_actual = data_scaled[-1]
        
        # D·ª± b√°o
        with torch.no_grad():
            Y_pred = model(X_input).numpy()[0]
        
        # T√≠nh sai s·ªë (Loss)
        target_idx = config.get('target_cols_idx', [0, 1, 2])
        loss = np.mean(np.abs(Y_pred[target_idx] - Y_actual[target_idx]))
        
        # So s√°nh v·ªõi ng∆∞·ª°ng
        if loss > config['threshold']:
            # Ph√¢n lo·∫°i l·ªói s∆° b·ªô
            if last_row['Speed'] < 1.5:
                err_type = "üê¢ K·∫πt t·∫£i / T·ªëc ƒë·ªô ch·∫≠m"
            else:
                err_type = "‚ö†Ô∏è Qu√° t·∫£i / Rung l·∫Øc"
                
            msg = (
                f"‚ö†Ô∏è **PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG (AI)**\n"
                f"---------------\n"
                f"ü§ñ Thi·∫øt b·ªã: `{dev_id}`\n"
                f"üìâ AI Score: **{loss:.3f}** (Ng∆∞·ª°ng: {config['threshold']:.2f})\n"
                f"üîß Lo·∫°i l·ªói: {err_type}\n"
                f"üèéÔ∏è T·ªëc ƒë·ªô: {last_row['Speed']}\n"
                f"üïí L√∫c: {last_row['time'].strftime('%H:%M:%S')}\n"
            )
            print(f"   -> üü† PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG AI (Loss: {loss:.3f})")
            send_telegram(msg)
        else:
            print(f"   -> ‚úÖ Ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng (Loss: {loss:.3f})")

    except Exception as e:
        print(f"‚ùå L·ªói kh√¥ng mong mu·ªën v·ªõi {dev_id}: {e}")

# ===============================================================
# 5. MAIN LOOP
# ===============================================================
if __name__ == "__main__":
    for dev in DEVICES:
        check_device_status(dev)
    
    print("\nüèÅ K·∫øt th√∫c phi√™n gi√°m s√°t.")