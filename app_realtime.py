import streamlit as st
import pandas as pd
import time
import plotly.graph_objects as go
import plotly.express as px
import numpy as np
import torch
import torch.nn as nn
import joblib
import os
from datetime import datetime, timedelta
from supabase import create_client

# ===============================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG & K·∫æT N·ªêI
# ===============================================================
st.set_page_config(page_title="H·ªá th·ªëng Gi√°m s√°t Nh√† m√°y", layout="wide", page_icon="üè≠")

# --- CSS: Giao di·ªán Tab tr√°i & Card ---
st.markdown("""
<style>
    /* Sidebar Styling */
    [data-testid="stSidebar"] {
        background-color: #f0f2f6;
        padding-top: 20px;
    }
    .stRadio > div {
        background-color: white;
        padding: 10px;
        border-radius: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    .stRadio label {
        font-weight: bold;
        font-size: 16px;
        padding: 10px 5px;
    }
    
    /* Card Styling */
    div[data-testid="stMetricValue"] { font-size: 22px !important; }
    .status-badge {
        padding: 5px 10px; border-radius: 6px; font-weight: bold; text-align: center; color: white;
    }
</style>
""", unsafe_allow_html=True)

# --- CONFIG THI·∫æT B·ªä & MODEL ---
# Logic: M√°y 1 g·ªìm L√†n 1,2. M√°y 2 g·ªìm L√†n 3,4.
# Gi·∫£ ƒë·ªãnh: M·ªói m√°y v·∫≠t l√Ω g·ª≠i l√™n Channel "01", "02". 
# N·∫øu m√°y 2 g·ª≠i "03", "04" trong DB, h√£y s·ª≠a channel_map b√™n d∆∞·ªõi.
MACHINE_CONFIG = {
    "M√ÅY 1": {
        "id": "4417930D77DA", # Thay ID th·ª±c t·∫ø c·ªßa M√°y 1
        "name": "M√ÅY C·∫ÆT 01",
        "lanes": [
            {"code": "L1", "name": "L√†n 1", "db_channel": "01"},
            {"code": "L2", "name": "L√†n 2", "db_channel": "02"}
        ]
    },
    "M√ÅY 2": {
        "id": "AC0BFBCE8797", # Thay ID th·ª±c t·∫ø c·ªßa M√°y 2
        "name": "M√ÅY C·∫ÆT 02",
        "lanes": [
            {"code": "L3", "name": "L√†n 3", "db_channel": "01"}, # Ho·∫∑c "03" t√πy DB
            {"code": "L4", "name": "L√†n 4", "db_channel": "02"}  # Ho·∫∑c "04" t√πy DB
        ]
    }
}

MODEL_PATH = "saved_models_v2/lstm_factory_v2.pth"
SCALER_PATH = "saved_models_v2/robust_scaler_v2.pkl"
CONFIG_PATH = "saved_models_v2/model_config_v2.pkl"
REFRESH_RATE = 2 

# --- SUPABASE ---
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
except:
    st.error("‚ùå L·ªói: Thi·∫øu Secrets SUPABASE")
    st.stop()

@st.cache_resource
def init_connection():
    return create_client(SUPABASE_URL, SUPABASE_KEY)
supabase = init_connection()

# --- LOAD AI MODEL ---
@st.cache_resource
def load_ai():
    # Ki·ªÉm tra file t·ªìn t·∫°i ƒë·ªÉ tr√°nh crash
    if not os.path.exists(CONFIG_PATH): return None, None, None
    try:
        cfg = joblib.load(CONFIG_PATH)
        scl = joblib.load(SCALER_PATH)
        
        # ƒê·ªãnh nghƒ©a l·∫°i class Model gi·ªëng h·ªát Notebook
        class LSTMModel(nn.Module):
            def __init__(self, n_features, hidden_dim=128, num_layers=3, dropout=0.2):
                super(LSTMModel, self).__init__()
                self.lstm = nn.LSTM(n_features, hidden_dim, num_layers, batch_first=True, dropout=dropout)
                self.fc = nn.Linear(hidden_dim, n_features)
            def forward(self, x):
                out, _ = self.lstm(x)
                out = self.fc(out[:, -1, :])
                return out

        model = LSTMModel(n_features=cfg['n_features'], hidden_dim=cfg['hidden_dim'])
        model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
        model.eval()
        return model, scl, cfg
    except Exception as e:
        print(f"L·ªói load AI: {e}")
        return None, None, None

model, scaler, config = load_ai()

# --- SESSION STATE ---
if 'logs' not in st.session_state:
    st.session_state.logs = [] # L∆∞u log chung

# ===============================================================
# 2. X·ª¨ L√ù D·ªÆ LI·ªÜU & AI
# ===============================================================
def get_realtime_data(limit=500): 
    """L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ DB"""
    try:
        response = supabase.table("sensor_data").select("*").order("time", desc=True).limit(limit).execute()
        df = pd.DataFrame(response.data)
        if not df.empty:
            df['time'] = pd.to_datetime(df['time'], format='mixed', utc=True)
            df['time'] = df['time'].dt.tz_convert('Asia/Bangkok').dt.tz_localize(None)
            df = df.sort_values('time')
        return df
    except: return pd.DataFrame()

def predict_anomaly(df_lane, model, scaler, config):
    """Logic d·ª± b√°o gi·ªëng h·ªát Notebook: Log1p -> Scale -> LSTM"""
    SEQ_LEN = 30
    if len(df_lane) < SEQ_LEN + 1: return 0.0, False
    try:
        features = config['features_list'] # ['Speed', 'd_RunTime', etc.]
        # L·∫•y ƒë√∫ng c√°c c·ªôt feature m√† model c·∫ßn
        data_segment = df_lane[features].tail(SEQ_LEN + 1).values
        
        # 1. Log Transform
        data_log = np.log1p(data_segment)
        # 2. Scale
        data_scaled = scaler.transform(data_log)
        
        # 3. Predict
        X_input = torch.tensor(data_scaled[:-1], dtype=torch.float32).unsqueeze(0)
        with torch.no_grad(): 
            Y_pred = model(X_input).numpy()[0]
            
        Y_actual = data_scaled[-1]
        
        # 4. Calculate Loss (Ch·ªâ tr√™n c√°c c·ªôt Target)
        target_idx = config.get('target_cols_idx', [0, 1, 2]) # Speed, RunTime, HeldTime
        loss = np.mean(np.abs(Y_pred[target_idx] - Y_actual[target_idx]))
        
        return loss, loss > config['threshold']
    except Exception as e: 
        return 0.0, False

def analyze_lane_status(df_lane):
    """Ph√¢n t√≠ch tr·∫°ng th√°i logic nghi·ªáp v·ª•"""
    if df_lane.empty: return "NODATA", "black", "Ch·ªù d·ªØ li·ªáu", 0.0
    
    last = df_lane.iloc[-1]
    now = datetime.now()
    
    # 1. Check Offline (> 3 ph√∫t kh√¥ng c√≥ tin)
    if (now - last['time']).total_seconds() > 180:
        return "OFFLINE", "gray", f"M·∫•t k·∫øt n·ªëi {last['time'].strftime('%H:%M')}", 0.0

    # 2. Check Crash (Nhi·ªát cao + D·ª´ng m√°y)
    if last['Speed'] == 0 and last.get('Temp', 0) > 40:
        return "CRASH", "red", f"‚ö†Ô∏è QU√Å NHI·ªÜT {last['Temp']}¬∞C", 9.9

    # 3. Check Idle
    if last['Speed'] < 0.1:
        return "IDLE", "#6c757d", "üí§ M√°y ƒëang ngh·ªâ", 0.0

    # 4. Check AI Anomaly
    loss, is_anom = predict_anomaly(df_lane, model, scaler, config) if model else (0.0, False)
    
    if is_anom:
        if last['Speed'] < 1.5: return "SLOW", "orange", "üê¢ Ch·∫°y ch·∫≠m b·∫•t th∆∞·ªùng", loss
        return "OVERLOAD", "red", "üî• Qu√° t·∫£i / B·∫•t th∆∞·ªùng", loss
        
    return "OK", "green", "‚úÖ ·ªîn ƒë·ªãnh", loss

# ===============================================================
# 3. UI COMPONENTS
# ===============================================================
def draw_gauge(value, title, color_code):
    fig = go.Figure(go.Indicator(
        mode = "gauge+number", value = value,
        title = {'text': title, 'font': {'size': 16}},
        gauge = {
            'axis': {'range': [None, 5]},
            'bar': {'color': color_code},
            'bgcolor': "white",
            'steps': [{'range': [0, 1.5], 'color': '#f8f9fa'}, {'range': [1.5, 5], 'color': '#e9ecef'}]
        }
    ))
    fig.update_layout(height=140, margin=dict(t=30, b=10, l=20, r=20))
    return fig

def render_lane_view(lane_cfg, df_lane):
    """Hi·ªÉn th·ªã giao di·ªán cho 1 L√†n"""
    st_code, color, msg, ai_loss = analyze_lane_status(df_lane)
    
    # Header Card
    with st.container(border=True):
        c1, c2 = st.columns([2, 1])
        c1.markdown(f"### üõ£Ô∏è {lane_cfg['name']}")
        c2.markdown(f'<div style="background-color:{color};" class="status-badge">{msg}</div>', unsafe_allow_html=True)
        st.divider()
        
        if not df_lane.empty:
            last = df_lane.iloc[-1]
            
            # Row 1: Gauge & Metrics
            kc1, kc2 = st.columns([1, 1])
            with kc1:
                st.plotly_chart(draw_gauge(last['Speed'], "T·ªëc ƒë·ªô (m/s)", color), use_container_width=True)
            with kc2:
                st.metric("üì¶ S·∫£n l∆∞·ª£ng", f"{int(last['Actual']):,}")
                st.metric("üå°Ô∏è Nhi·ªát ƒë·ªô", f"{last.get('Temp', 0):.1f}¬∞C")
                st.metric("üß† AI Loss", f"{ai_loss:.4f}", delta_color="inverse")

            # Row 2: Sparkline Chart
            chart_df = df_lane.tail(50)
            fig = px.area(chart_df, x='time', y='Speed', height=100)
            fig.update_layout(margin=dict(l=0,r=0,t=0,b=0), xaxis=dict(visible=False), yaxis=dict(visible=False), showlegend=False)
            fig.update_traces(line_color=color, fillcolor=color, fill_opacity=0.1)
            st.plotly_chart(fig, use_container_width=True)
            
            # Log Warning
            if st_code in ["CRASH", "SLOW", "OVERLOAD"]:
                log_entry = f"{datetime.now().strftime('%H:%M:%S')} - {lane_cfg['name']}: {msg}"
                if not st.session_state.logs or st.session_state.logs[-1] != log_entry:
                    st.session_state.logs.append(log_entry)

# ===============================================================
# 4. MAIN LAYOUT
# ===============================================================

# --- A. SIDEBAR ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2620/2620952.png", width=70) # Factory Icon
    st.title("STANLEY IoT")
    st.caption(f"Update: {datetime.now().strftime('%H:%M:%S')}")
    st.markdown("---")
    
    # 3 TAB CH√çNH
    selected_tab = st.radio(
        "KHU V·ª∞C GI√ÅM S√ÅT:", 
        ["üèóÔ∏è M√ÅY 1 (L√†n 1-2)", "üèóÔ∏è M√ÅY 2 (L√†n 3-4)", "üìä ANALYTICS"],
        captions=["Device 77DA", "Device 8797", "B√°o c√°o l·ªãch s·ª≠"]
    )
    
    st.markdown("---")
    if st.session_state.logs:
        st.warning("üîî C·∫£nh b√°o g·∫ßn ƒë√¢y:")
        for l in st.session_state.logs[-3:]:
            st.caption(l)

# --- B. X·ª¨ L√ù D·ªÆ LI·ªÜU CHUNG ---
df_all = get_realtime_data(1000)

# --- C. HI·ªÇN TH·ªä N·ªòI DUNG THEO TAB ---

# === TAB 1: M√ÅY 1 ===
if "M√ÅY 1" in selected_tab:
    cfg = MACHINE_CONFIG["M√ÅY 1"]
    st.header(f"üì° {cfg['name']} - Realtime Monitor")
    
    col_left, col_right = st.columns(2)
    
    # Filter Data for Device 1
    df_dev = df_all[df_all['DevAddr'] == cfg['id']]
    
    with col_left:
        lane_info = cfg['lanes'][0]
        df_l = df_dev[df_dev['Channel'] == lane_info['db_channel']].sort_values('time')
        render_lane_view(lane_info, df_l)
        
    with col_right:
        lane_info = cfg['lanes'][1]
        df_l = df_dev[df_dev['Channel'] == lane_info['db_channel']].sort_values('time')
        render_lane_view(lane_info, df_l)

# === TAB 2: M√ÅY 2 ===
elif "M√ÅY 2" in selected_tab:
    cfg = MACHINE_CONFIG["M√ÅY 2"]
    st.header(f"üì° {cfg['name']} - Realtime Monitor")
    
    col_left, col_right = st.columns(2)
    
    # Filter Data for Device 2
    df_dev = df_all[df_all['DevAddr'] == cfg['id']]
    
    with col_left:
        lane_info = cfg['lanes'][0] # L√†n 3
        df_l = df_dev[df_dev['Channel'] == lane_info['db_channel']].sort_values('time')
        render_lane_view(lane_info, df_l)
        
    with col_right:
        lane_info = cfg['lanes'][1] # L√†n 4
        df_l = df_dev[df_dev['Channel'] == lane_info['db_channel']].sort_values('time')
        render_lane_view(lane_info, df_l)

# === TAB 3: ANALYTICS ===
else:
    st.header("üìä Ph√¢n T√≠ch & B√°o C√°o Hi·ªáu Su·∫•t")
    st.markdown("---")
    
    # Analytics Controls
    c1, c2, c3 = st.columns([1, 1, 2])
    with c1:
        m_sel = st.selectbox("Ch·ªçn M√°y:", ["M√ÅY 1", "M√ÅY 2"])
    with c2:
        d_sel = st.slider("Xem l·∫°i (ng√†y):", 1, 30, 7)
    
    if st.button("üîç T·∫£i d·ªØ li·ªáu l·ªãch s·ª≠"):
        sel_id = MACHINE_CONFIG[m_sel]['id']
        start_date = (datetime.utcnow() - timedelta(days=d_sel)).isoformat()
        
        # Query History
        res = supabase.table("sensor_data").select("*")\
            .eq("DevAddr", sel_id).gte("time", start_date).order("time").execute()
        df_hist = pd.DataFrame(res.data)
        
        if not df_hist.empty:
            df_hist['time'] = pd.to_datetime(df_hist['time']).dt.tz_convert('Asia/Bangkok')
            
            # T√°ch Channel ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì so s√°nh
            fig = px.line(df_hist, x='time', y='Speed', color='Channel', 
                          title=f"Bi·ªÉu ƒë·ªì t·ªëc ƒë·ªô: {m_sel}", height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # Th·ªëng k√™
            c_stat1, c_stat2 = st.columns(2)
            c_stat1.metric("T·ªïng s·∫£n l∆∞·ª£ng", f"{int(df_hist['Actual'].max() - df_hist['Actual'].min()):,}")
            c_stat2.metric("Nhi·ªát ƒë·ªô TB", f"{df_hist['Temp'].mean():.1f}¬∞C")
            
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu trong kho·∫£ng th·ªùi gian n√†y.")

# Auto Refresh logic
time.sleep(REFRESH_RATE)
st.rerun()